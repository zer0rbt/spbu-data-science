{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:17.872964700Z",
     "start_time": "2024-11-16T03:50:17.706393600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "from typing import Tuple, Any\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import configparser\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:17.958596600Z",
     "start_time": "2024-11-16T03:50:17.879970800Z"
    }
   },
   "id": "2347c4495e55becf",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_config(config_file='config.yaml'):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = load_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:18.021768500Z",
     "start_time": "2024-11-16T03:50:17.915420500Z"
    }
   },
   "id": "41d0cbf7c4237b19",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset initialisation.\n",
    "        :param root_dir: Path to the directory with the images.\n",
    "        :param transform: Transforms applied to the data.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for mushroom_name in os.listdir(root_dir):\n",
    "            mushroom_folder = os.path.join(root_dir, mushroom_name)\n",
    "            if os.path.isdir(mushroom_folder):\n",
    "                for image_name in os.listdir(mushroom_folder):\n",
    "                    if image_name.endswith(('.png', '.jpg', '.jpeg')):  # проверяем типы изображений\n",
    "                        self.image_paths.append(os.path.join(mushroom_folder, image_name))\n",
    "                        self.labels.append(mushroom_name)\n",
    "\n",
    "        # Создаем словарь для быстрого поиска меток\n",
    "        self.class_to_idx = {label: idx for idx, label in enumerate(sorted(set(self.labels)))}\n",
    "        self.idx_to_class = {idx: label for label, idx in self.class_to_idx.items()}\n",
    "        self.labels = [self.class_to_idx[label] for label in self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:18.068285Z",
     "start_time": "2024-11-16T03:50:17.985593Z"
    }
   },
   "id": "ce14575a365231b0",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Изменяем размер изображений (можно выбрать другой размер)\n",
    "    transforms.ToTensor(),  # Преобразуем изображение в тензор\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Нормализация\n",
    "])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:18.231540200Z",
     "start_time": "2024-11-16T03:50:18.080287800Z"
    }
   },
   "id": "7779f2499ef752c8",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Создаем объект датасета\n",
    "dataset = MushroomDataset(root_dir=config['mushrooms']['dataset'], transform=transform)\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки (например, 80% - 20%)\n",
    "train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем даталоадеры\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T04:00:43.038581300Z",
     "start_time": "2024-11-16T04:00:41.514184200Z"
    }
   },
   "id": "a802c7fd31db0658",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c834587cd42d1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:18.534355500Z",
     "start_time": "2024-11-16T03:50:18.465030200Z"
    }
   },
   "id": "852acaee1c154b0",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define a train function, model-agnostic, which will be used for further training\n",
    "def train(net, train_loader, device, num_epochs, learning_rate):\n",
    "    \n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    acc_history = []\n",
    "\n",
    "    with tqdm(total=len(train_loader)*num_epochs, position=0, leave=True) as pbar:\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0 \n",
    "            \n",
    "            for batch_num, (inputs, labels) in enumerate(train_loader):\n",
    "                # Possibly copy inputs and labels to the GPU\n",
    "                # batch x [48, 48, 1] -> batch x [1, 48, 48]\n",
    "                # inputs = inputs.permute(0, 3, 1, 2).to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = net(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                # Backpropagation                \n",
    "                loss.backward()\n",
    "\n",
    "                # Update\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print progress\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Calculate batch Accuracy\n",
    "                _, predicted = outputs.max(1)\n",
    "                batch_total = labels.size(0)\n",
    "                batch_correct = predicted.eq(labels).sum().item()\n",
    "                batch_acc = batch_correct/batch_total\n",
    "                \n",
    "                pbar.set_description(\"Epoch: %d, Batch: %2d, Loss: %.2f, Acc: %.2f\" % (epoch, batch_num, running_loss, batch_acc))\n",
    "                pbar.update()\n",
    "\n",
    "                total += batch_total\n",
    "                correct += batch_correct\n",
    "\n",
    "            # Print the evaluation metric and reset it for the next epoch\n",
    "            acc = correct/total \n",
    "            acc_history.append(acc)\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "    return acc_history\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T04:02:14.442270600Z",
     "start_time": "2024-11-16T04:02:14.409184Z"
    }
   },
   "id": "2086a95649142c6e",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_history(history, title):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(history)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T04:02:16.490313300Z",
     "start_time": "2024-11-16T04:02:16.438023Z"
    }
   },
   "id": "ea5a99ca790d46bf",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:18.660169500Z",
     "start_time": "2024-11-16T03:50:18.548364800Z"
    }
   },
   "id": "428cb770d49f868d",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "\n",
    "# hist = train(net, train_dataloader, device, EPOCHS, LR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T03:50:18.721144400Z",
     "start_time": "2024-11-16T03:50:18.563570300Z"
    }
   },
   "id": "c25e38c6ed7aba34",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def build_MOCNN_S():\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.01)\n",
    "        elif isinstance(m, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.01)\n",
    "    \n",
    "    # Строим модель\n",
    "    mocnn = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3, 32, kernel_size=5, padding=2),  # Вход: 3 канала (RGB)\n",
    "        torch.nn.ReLU(),\n",
    "        \n",
    "        torch.nn.AvgPool2d(kernel_size=6, stride=6),\n",
    "        \n",
    "        torch.nn.Conv2d(32, 40, kernel_size=5, padding=2),  # Вход: 3 канала (RGB)\n",
    "        torch.nn.ReLU(),\n",
    "        \n",
    "        torch.nn.AvgPool2d(kernel_size=4, stride=4),# После AvgPool размер будет 32x16x16\n",
    "        \n",
    "        torch.nn.Flatten(),\n",
    "        \n",
    "        # Размерность после свертки и пулинга будет 32 * 16 * 16 = 8192\n",
    "        torch.nn.Linear(3240, 120),\n",
    "        torch.nn.Sigmoid(),\n",
    "        \n",
    "        torch.nn.Linear(120, 84),\n",
    "        torch.nn.Sigmoid(),\n",
    "        \n",
    "        torch.nn.Linear(84, 10)  # Количество выходных нейронов зависит от количества классов\n",
    "    )\n",
    "  \n",
    "    # Применяем инициализацию\n",
    "    mocnn.apply(init_weights)\n",
    "    \n",
    "    return mocnn\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T04:04:07.672237Z",
     "start_time": "2024-11-16T04:04:07.525273600Z"
    }
   },
   "id": "5c80dc5c40d3efbd",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): AvgPool2d(kernel_size=6, stride=6, padding=0)\n",
      "  (3): Conv2d(32, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=3240, out_features=120, bias=True)\n",
      "  (8): Sigmoid()\n",
      "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (10): Sigmoid()\n",
      "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mocnn = build_MOCNN_S()\n",
    "print(mocnn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-16T04:04:10.506090800Z",
     "start_time": "2024-11-16T04:04:10.292559800Z"
    }
   },
   "id": "b23c2a4b8bf2e932",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 52, Loss: 42617.77, Acc: 0.09:   0%|          | 53/16800 [01:23<6:57:59,  1.50s/it]"
     ]
    }
   ],
   "source": [
    "mocnn_hist = train(mocnn, train_loader, device, EPOCHS, 32)\n",
    "print_history(mocnn_hist, \"NN Model Accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-16T04:04:13.062349Z"
    }
   },
   "id": "7f59c4bb64a4d114",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
